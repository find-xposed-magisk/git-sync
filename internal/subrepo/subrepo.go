package subrepo

import (
	"bytes"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/find-xposed-magisk/git-sync/internal/config"
	"github.com/find-xposed-magisk/git-sync/internal/git"
	"github.com/find-xposed-magisk/git-sync/internal/logger"
)

// SubrepoProcessor ç‰¹æ®Šä»“åº“å¤„ç†å™¨
// Special repository processor
type SubrepoProcessor struct {
	cfg       *config.Config
	gitOps    *git.GitOps
	logger    *logger.Logger
	hashCache *HashCache // hashç¼“å­˜ / Hash cache
}

// NewSubrepoProcessor åˆ›å»ºç‰¹æ®Šä»“åº“å¤„ç†å™¨
// Creates a new special repository processor
func NewSubrepoProcessor(cfg *config.Config, gitOps *git.GitOps, log *logger.Logger) *SubrepoProcessor {
	return &SubrepoProcessor{
		cfg:       cfg,
		gitOps:    gitOps,
		logger:    log,
		hashCache: NewHashCache(), // åˆå§‹åŒ–hashç¼“å­˜ / Initialize hash cache
	}
}

// fileOperation æ–‡ä»¶æ“ä½œç»“æœ
// File operation result
type fileOperation struct {
	mode string
	hash string
	path string
}

// subrepoJob å­ä»“åº“å¤„ç†ä»»åŠ¡
// Subrepo processing job
type subrepoJob struct {
	path string // ä»“åº“å®Œæ•´è·¯å¾„ / Full repository path
	name string // ä»“åº“åç§° / Repository name
}

// ProcessAllSubrepos å¤„ç†æ‰€æœ‰ç‰¹æ®Šä»“åº“ï¼ˆå¹¶å‘ä¼˜åŒ–ç‰ˆï¼‰
// Processes all special repositories (concurrent optimized version)
func (sp *SubrepoProcessor) ProcessAllSubrepos() error {
	sp.logger.Phase("éƒ¨åˆ†Aï¼šåè°ƒå­ä»“åº“çŠ¶æ€ (å¹¶å‘æ¨¡å¼) / Part A: Reconciling sub-repository states (Concurrent Mode)")
	
	// é˜¶æ®µ1ï¼šæ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å­ä»“åº“ç›®å½•
	// Phase 1: Collect all sub-repository directories to process
	subrepoMap := make(map[string]bool)
	
	for _, baseDir := range sp.cfg.SubrepoBaseDirs {
		basePath := filepath.Join(sp.cfg.RepoRoot, baseDir)
		
		// æ·»åŠ base_diræœ¬èº«
		// Add base_dir itself
		if info, err := os.Stat(basePath); err == nil && info.IsDir() {
			subrepoMap[baseDir] = true
		}
		
		// æŸ¥æ‰¾ä¸€çº§å­ç›®å½•
		// Find first-level subdirectories
		if entries, err := os.ReadDir(basePath); err == nil {
			for _, entry := range entries {
				if entry.IsDir() {
					subPath := filepath.Join(baseDir, entry.Name())
					subrepoMap[subPath] = true
				}
			}
		}
		
		// ä»Gitç´¢å¼•ä¸­è·å–å·²è¿½è¸ªçš„ç›®å½•
		// Get tracked directories from git index
		files, err := sp.gitOps.ListFiles("-d", "--name-only", "HEAD", baseDir)
		if err == nil {
			for _, file := range files {
				if file != "" {
					subrepoMap[file] = true
				}
			}
		}
	}
	
	// é˜¶æ®µ2ï¼šç­›é€‰ç‰¹æ®Šä»“åº“å¹¶å‡†å¤‡å¹¶å‘ä»»åŠ¡
	// Phase 2: Filter special repos and prepare concurrent jobs
	var jobs []subrepoJob
	for subrepoDir := range subrepoMap {
		subrepoPath := filepath.Join(sp.cfg.RepoRoot, subrepoDir)
		subrepoName := filepath.Base(subrepoDir)
		
		// æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šä»“åº“
		// Check if it's a special repository
		if sp.isSpecialRepo(subrepoPath) {
			jobs = append(jobs, subrepoJob{
				path: subrepoPath,
				name: subrepoName,
			})
		}
	}
	
	numRepos := len(jobs)
	if numRepos == 0 {
		sp.logger.Info("æ— ç‰¹æ®Šä»“åº“éœ€è¦å¤„ç† / No special repositories to process")
		return nil
	}
	
	// é˜¶æ®µ3ï¼šè®¾ç½®å¹¶å‘å¤„ç† Worker Pool
	// Phase 3: Set up concurrent processing Worker Pool
	// ä½¿ç”¨é…ç½®çš„workeræ•°é‡ï¼Œä½†ä¸è¶…è¿‡ä»“åº“æ•°é‡
	// Use configured worker count, but don't exceed number of repos
	numWorkers := sp.cfg.MaxParallelWorkers
	if numWorkers > numRepos {
		numWorkers = numRepos
	}
	
	jobsChan := make(chan subrepoJob, numRepos)
	errsChan := make(chan error, numRepos)
	var wg sync.WaitGroup
	
	sp.logger.Info("ğŸš€ å¯åŠ¨å¹¶å‘å¤„ç†ï¼š%d ä¸ªç‰¹æ®Šä»“åº“ï¼Œ%d ä¸ªå¹¶å‘worker / Starting concurrent processing: %d special repos with %d workers", 
		numRepos, numWorkers, numRepos, numWorkers)
	
	// é˜¶æ®µ4ï¼šå¯åŠ¨ worker goroutines
	// Phase 4: Start worker goroutines
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for job := range jobsChan {
				sp.logger.Info("[Worker %d] åè°ƒç‰¹æ®Šä»“åº“ / Reconciling special repo: %s", workerID, job.name)
				if err := sp.processSpecialRepoFastAndSafe(job.path, job.name); err != nil {
					// è£…é¥°é”™è¯¯ä¿¡æ¯å¹¶å‘é€åˆ°é”™è¯¯é€šé“
					// Decorate error with context and send to error channel
					errsChan <- fmt.Errorf("[Worker %d] å¤„ç†ä»“åº“ %s å¤±è´¥ / Failed to process repo %s: %w", 
						workerID, job.name, job.name, err)
				} else {
					sp.logger.Debug("[Worker %d] âœ“ å®Œæˆ / Completed: %s", workerID, job.name)
				}
			}
		}(i + 1)
	}
	
	// é˜¶æ®µ5ï¼šåˆ†å‘ä»»åŠ¡åˆ° workers
	// Phase 5: Distribute jobs to workers
	for _, job := range jobs {
		jobsChan <- job
	}
	close(jobsChan) // å‘é€å®Œæ¯•ï¼Œå…³é—­ä»»åŠ¡é€šé“ / All jobs sent, close channel
	
	// é˜¶æ®µ6ï¼šç­‰å¾…æ‰€æœ‰ workers å®Œæˆå¹¶æ”¶é›†é”™è¯¯
	// Phase 6: Wait for all workers to finish and collect errors
	wg.Wait()
	close(errsChan)
	
	var processingErrors []string
	for err := range errsChan {
		sp.logger.Error(err.Error())
		processingErrors = append(processingErrors, err.Error())
	}
	
	if len(processingErrors) > 0 {
		return fmt.Errorf("%d/%d ä¸ªä»“åº“å¤„ç†å¤±è´¥ / %d/%d repositories failed to process:\n- %s",
			len(processingErrors),
			numRepos,
			len(processingErrors),
			numRepos,
			strings.Join(processingErrors, "\n- "),
		)
	}
	
	sp.logger.Info("âœ… æˆåŠŸå¤„ç†æ‰€æœ‰ %d ä¸ªç‰¹æ®Šä»“åº“ / Successfully processed all %d special repositories", numRepos, numRepos)
	sp.logger.Debug("--- éƒ¨åˆ†Aï¼šå­ä»“åº“åè°ƒå®Œæˆ / Part A: Sub-repository reconciliation complete ---")
	return nil
}

// isSpecialRepo æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šä»“åº“
// Checks if it's a special repository
func (sp *SubrepoProcessor) isSpecialRepo(path string) bool {
	// æ£€æŸ¥.gitç›®å½•
	// Check for .git directory
	if info, err := os.Stat(filepath.Join(path, ".git")); err == nil && info.IsDir() {
		return true
	}
	
	// æ£€æŸ¥gitdirç›®å½•
	// Check for gitdir directory
	if info, err := os.Stat(filepath.Join(path, "gitdir")); err == nil && info.IsDir() {
		return true
	}
	
	// æ£€æŸ¥gitdir.taræ–‡ä»¶
	// Check for gitdir.tar file
	if info, err := os.Stat(filepath.Join(path, "gitdir.tar")); err == nil && !info.IsDir() {
		return true
	}
	
	return false
}

// processSpecialRepoFastAndSafe é«˜æ€§èƒ½å®‰å…¨å¤„ç†ç‰¹æ®Šä»“åº“
// High-performance safe processing of special repository
func (sp *SubrepoProcessor) processSpecialRepoFastAndSafe(subrepoDir, subrepoName string) error {
	startTime := time.Now()
	sp.logger.Debug("ä½¿ç”¨é«˜æ€§èƒ½å®‰å…¨æ¨¡å¼ / Using high-performance safe mode")
	
	// æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
	// Check if directory exists
	if _, err := os.Stat(subrepoDir); os.IsNotExist(err) {
		sp.logger.Info("ç¡®è®¤åˆ é™¤ / Confirmed deletion of: %s", subrepoName)
		// åˆ é™¤ç´¢å¼•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
		// Remove all files from index
		files, err := sp.gitOps.ListFiles(subrepoDir)
		if err == nil {
			for _, file := range files {
				if file != "" {
					sp.gitOps.Remove(file)
				}
			}
		}
		return nil
	}
	
	// åˆ›å»ºå½“å‰ç´¢å¼•çŠ¶æ€çš„å¤‡ä»½
	// Create backup of current index state
	backupStart := time.Now()
	sp.logger.Debug("åˆ›å»ºå®‰å…¨å¤‡ä»½ / Creating safety backup")
	indexBackup, err := sp.gitOps.ListFiles("-s", subrepoDir)
	sp.logger.Debug("å¤‡ä»½å®Œæˆï¼Œè€—æ—¶ / Backup complete, took: %v", time.Since(backupStart))
	if err != nil {
		sp.logger.Warn("Failed to create index backup: %v", err)
	}
	
	// æ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶
	// Collect files to process
	collectStart := time.Now()
	sp.logger.Debug("é«˜æ•ˆæ”¶é›†æ–‡ä»¶ / Efficiently collecting files")
	sp.logger.Debug("  â†³ æ‰«æç›®å½• / Scanning directory: %s", subrepoDir)
	
	// æ”¶é›†å·¥ä½œæ–‡ä»¶ï¼ˆæ’é™¤è™šæ‹Ÿç¯å¢ƒï¼‰
	// Collect work files (excluding virtual environments)
	workFiles, excludedDirs, err := sp.collectWorkFiles(subrepoDir)
	if err != nil {
		return fmt.Errorf("failed to collect work files: %v", err)
	}
	
	if len(excludedDirs) > 0 {
		sp.logger.Info("æ’é™¤äº† %d ä¸ªè™šæ‹Ÿç¯å¢ƒç›®å½• / Excluded %d virtual env directories", len(excludedDirs), len(excludedDirs))
		if len(excludedDirs) <= 20 {
			for _, dir := range excludedDirs {
				sp.logger.Debug("  â€¢ %s", dir)
			}
		} else {
			sp.logger.Debug("  â€¢ %s ... (å…±%dä¸ª)", excludedDirs[0], len(excludedDirs))
		}
	}
	
	sp.logger.Info("æ”¶é›†åˆ° %d ä¸ªå·¥ä½œæ–‡ä»¶ / Collected %d work files", len(workFiles), len(workFiles))
	sp.logger.Debug("å·¥ä½œæ–‡ä»¶æ”¶é›†å®Œæˆï¼Œè€—æ—¶ / Work files collected, took: %v", time.Since(collectStart))
	if err != nil {
		return fmt.Errorf("failed to collect work files: %v", err)
	}
	
	gitCollectStart := time.Now()
	gitFiles, err := sp.collectGitFiles(subrepoDir)
	if err != nil {
		return fmt.Errorf("failed to collect git files: %v", err)
	}
	sp.logger.Debug("Gitæ–‡ä»¶æ”¶é›†å®Œæˆï¼Œè€—æ—¶ / Git files collected, took: %v", time.Since(gitCollectStart))
	
	totalFiles := len(workFiles) + len(gitFiles)
	sp.logger.Debug("é«˜é€Ÿå¤„ç† %d ä¸ªæ–‡ä»¶ / High-speed processing %d files", totalFiles, totalFiles)
	
	// æ™ºèƒ½æ–‡ä»¶åˆ†ç±»å¤„ç†
	// Intelligent file classification processing
	operations := make([]fileOperation, 0, totalFiles)
	var mu sync.Mutex
	var wg sync.WaitGroup
	
	// åˆ›å»ºå·¥ä½œæ± 
	// Create worker pool
	sem := make(chan struct{}, sp.cfg.MaxParallelWorkers)
	
	// åˆ†ç±»æ–‡ä»¶ï¼ˆä½¿ç”¨é…ç½®çš„é˜ˆå€¼ï¼‰
	// Classify files (using configured thresholds)
	smallFiles := []string{}   // < SmallFileThreshold
	mediumFiles := []string{}  // SmallFileThreshold - MediumFileThreshold
	largeFiles := []string{}   // > MediumFileThreshold

	for _, fp := range workFiles {
		if info, err := os.Stat(fp); err == nil {
			fileSize := info.Size()
			if fileSize < sp.cfg.SmallFileThreshold {
				smallFiles = append(smallFiles, fp)
			} else if fileSize < sp.cfg.MediumFileThreshold {
				mediumFiles = append(mediumFiles, fp)
			} else {
				largeFiles = append(largeFiles, fp)
			}
		}
	}
	
	sp.logger.Debug("æ–‡ä»¶åˆ†ç±» / File classification: å°æ–‡ä»¶ %d, ä¸­æ–‡ä»¶ %d, å¤§æ–‡ä»¶ %d / small %d, medium %d, large %d",
		len(smallFiles), len(mediumFiles), len(largeFiles), len(smallFiles), len(mediumFiles), len(largeFiles))
	
	// å¤„ç†å°æ–‡ä»¶ï¼ˆå¹¶è¡Œï¼‰
	// Process small files (parallel)
	if len(smallFiles) > 0 {
		sp.logger.Debug("å¹¶è¡Œå¤„ç†å°æ–‡ä»¶ / Parallel processing small files")
		smallStart := time.Now()
		
		for _, filePath := range smallFiles {
			wg.Add(1)
			go func(fp string) {
				defer wg.Done()
				sem <- struct{}{}
				defer func() { <-sem }()
				
				if op, err := sp.processWorkFile(fp); err == nil {
					mu.Lock()
					operations = append(operations, op)
					mu.Unlock()
				}
			}(filePath)
		}
		wg.Wait()
		sp.logger.Debug("å°æ–‡ä»¶å¤„ç†å®Œæˆï¼Œè€—æ—¶ / Small files processed, took: %v", time.Since(smallStart))
	}
	
	// å¤„ç†ä¸­æ–‡ä»¶ï¼ˆä¸²è¡Œï¼‰
	// Process medium files (serial)
	if len(mediumFiles) > 0 {
		sp.logger.Debug("ä¸²è¡Œå¤„ç†ä¸­æ–‡ä»¶ / Serial processing medium files")
		mediumStart := time.Now()
		
		for _, filePath := range mediumFiles {
			if op, err := sp.processWorkFile(filePath); err == nil {
				operations = append(operations, op)
			}
		}
		sp.logger.Debug("ä¸­æ–‡ä»¶å¤„ç†å®Œæˆï¼Œè€—æ—¶ / Medium files processed, took: %v", time.Since(mediumStart))
	}
	
	// å¤„ç†å¤§æ–‡ä»¶ï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
	// Process large files (special handling)
	if len(largeFiles) > 0 {
		sp.logger.Warn("ç‰¹æ®Šå¤„ç†å¤§æ–‡ä»¶ / Special processing large files: %d ä¸ª / %d files", len(largeFiles), len(largeFiles))
		largeStart := time.Now()
		
		for _, filePath := range largeFiles {
			fileInfo, _ := os.Stat(filePath)
			fileSize := fileInfo.Size()
			sp.logger.Info("å¤„ç†å¤§æ–‡ä»¶ / Processing large file: %s (%.2f MB)", 
				filePath, float64(fileSize)/1024/1024)
			
			if op, err := sp.processWorkFile(filePath); err == nil {
				operations = append(operations, op)
			}
		}
		sp.logger.Info("å¤§æ–‡ä»¶å¤„ç†å®Œæˆï¼Œè€—æ—¶ / Large files processed, took: %v", time.Since(largeStart))
	}
	
	// å¤„ç†.gitæ–‡ä»¶ï¼ˆå¹¶è¡Œï¼‰
	// Process .git files (parallel)
	if len(gitFiles) > 0 {
		sp.logger.Debug("å¹¶è¡Œè½¬æ¢ git ç›®å½• / Parallel converting git directory")
		gitStart := time.Now()
		
		for _, filePath := range gitFiles {
			wg.Add(1)
			go func(fp string) {
				defer wg.Done()
				sem <- struct{}{}
				defer func() { <-sem }()
				
				if op, err := sp.processGitFile(fp, subrepoDir); err == nil {
					mu.Lock()
					operations = append(operations, op)
					mu.Unlock()
				}
			}(filePath)
		}
		wg.Wait()
		sp.logger.Debug("Gitæ–‡ä»¶è½¬æ¢å®Œæˆï¼Œè€—æ—¶ / Git files converted, took: %v", time.Since(gitStart))
	}
	
	// ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
	// Wait for all tasks to complete
	processStart := time.Now()
	wg.Wait()
	processDuration := time.Since(processStart)
	
	sp.logger.Info("å·²å‡†å¤‡ %d ä¸ªæ–‡ä»¶æ“ä½œ / Prepared %d file operations", len(operations), len(operations))
	sp.logger.Debug("å¹¶è¡Œå¤„ç†è€—æ—¶ / Parallel processing took: %v (é€Ÿåº¦ / speed: %.0f files/sec)", 
		processDuration, float64(totalFiles)/processDuration.Seconds())
	
	// å®‰å…¨çš„åŸå­æ€§åº”ç”¨æ‰€æœ‰å˜æ›´
	// Safely apply all changes atomically
	if len(operations) > 0 {
		batchStart := time.Now()
		sp.logger.Debug("å®‰å…¨åŸå­æ€§åº”ç”¨å˜æ›´ / Safely applying changes atomically")
		
		// æ‰¹é‡åº”ç”¨æ‰€æœ‰æ“ä½œï¼ˆä½¿ç”¨å•ä¸ªgit update-index --index-infoå‘½ä»¤ï¼‰
		// Batch apply all operations (using single git update-index --index-info command)
		if err := sp.batchUpdateIndex(operations); err != nil {
			sp.logger.Error("Failed to batch update index: %v", err)
			return fmt.Errorf("failed to batch update index: %v", err)
		}
		sp.logger.Debug("æ‰¹é‡æ›´æ–°è€—æ—¶ / Batch update took: %v", time.Since(batchStart))
		
		// æ¸…ç†ä¸å†å­˜åœ¨çš„æ–‡ä»¶
		// Clean up files that no longer exist
		cleanupStart := time.Now()
		if len(indexBackup) > 0 {
			sp.logger.Debug("å¼€å§‹æ¸…ç†ä¸å­˜åœ¨çš„æ–‡ä»¶ / Starting cleanup of non-existent files: %d ä¸ªç´¢å¼•æ¡ç›® / %d index entries", 
				len(indexBackup), len(indexBackup))
			
			operationPaths := make(map[string]bool)
			for _, op := range operations {
				operationPaths[op.path] = true
			}
			
			filesToRemove := []string{}
			
			for _, line := range indexBackup {
				if line == "" {
					continue
				}
				
				// è§£æç´¢å¼•è¡Œ: mode hash stage path
				// Parse index line: mode hash stage path
				parts := strings.Fields(line)
				if len(parts) < 4 {
					continue
				}
				
				path := strings.Join(parts[3:], " ")
				
				// å»é™¤å¼•å·å’Œè§£ç å…«è¿›åˆ¶è½¬ä¹‰ï¼ˆå¤„ç†åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„è·¯å¾„ï¼‰
				// Remove quotes and decode octal escapes (handle paths with special characters)
				path = unquoteGitPath(path)
				
				// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥åˆ é™¤
				// Check if file should be deleted
				shouldDelete := false
				
				// å¦‚æœæ˜¯.gitè·¯å¾„ï¼Œæ£€æŸ¥å¯¹åº”çš„gitdirè·¯å¾„
				// If it's a .git path, check corresponding gitdir path
				if strings.Contains(path, "/.git/") {
					gitdirPath := strings.Replace(path, "/.git/", "/gitdir/", 1)
					if !operationPaths[gitdirPath] {
						fullPath := filepath.Join(sp.cfg.RepoRoot, path)
						if _, err := os.Stat(fullPath); os.IsNotExist(err) {
							shouldDelete = true
						}
					}
				} else {
					// å¯¹äºé.gitæ–‡ä»¶ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
					// For non-.git files, check if file exists
					if !operationPaths[path] {
						fullPath := filepath.Join(sp.cfg.RepoRoot, path)
						if _, err := os.Stat(fullPath); os.IsNotExist(err) {
							shouldDelete = true
						}
					}
				}
				
				if shouldDelete {
					filesToRemove = append(filesToRemove, path)
				}
			}
			
			// æ‰¹é‡åˆ é™¤
			// Batch remove
			if len(filesToRemove) > 0 {
				sp.logger.Debug("æ‰¹é‡åˆ é™¤ %d ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶ / Batch removing %d non-existent files", 
					len(filesToRemove), len(filesToRemove))
				
				// ä½¿ç”¨å•ä¸ªgit rmå‘½ä»¤æ‰¹é‡åˆ é™¤
				// Use single git rm command for batch removal
				if err := sp.batchRemoveFiles(filesToRemove); err != nil {
					sp.logger.Warn("Failed to batch remove files: %v", err)
				}
			}
			
			sp.logger.Debug("æ¸…ç†å®Œæˆï¼Œè€—æ—¶ / Cleanup complete, took: %v", time.Since(cleanupStart))
		}
		
		// ç¡®ä¿gitdirç›®å½•ç»“æ„å­˜åœ¨ï¼Œå¹¶ä»ç´¢å¼•æ£€å‡ºæ–‡ä»¶åˆ°å·¥ä½œç›®å½•
		// Ensure gitdir directory structure exists and checkout files from index to working directory
		// ä¸ Shell ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼šç´¢å¼•ä¸­çš„ gitdir æ–‡ä»¶éœ€è¦å®é™…å­˜åœ¨äºå·¥ä½œç›®å½•
		// Shell-compatible: gitdir files in index should also exist in working directory
		if len(gitFiles) > 0 {
			sp.logger.Debug("åˆ›å»ºgitdirç›®å½•ç»“æ„å¹¶æ£€å‡ºæ–‡ä»¶ / Creating gitdir directory structure and checking out files")
			
			// è·å–è¯¥å­ä»“åº“çš„æ‰€æœ‰ gitdir æ–‡ä»¶
			// Get all gitdir files for this subrepo
			relSubrepoDir, _ := filepath.Rel(sp.cfg.RepoRoot, subrepoDir)
			gitdirPrefix := filepath.Join(relSubrepoDir, "gitdir")
			gitdirFiles, err := sp.gitOps.ListFiles(gitdirPrefix)
			if err == nil && len(gitdirFiles) > 0 {
				for _, gitdirFile := range gitdirFiles {
					if gitdirFile == "" {
						continue
					}
					
					// åˆ›å»ºç›®å½•ç»“æ„
					// Create directory structure
					fullPath := filepath.Join(sp.cfg.RepoRoot, gitdirFile)
					if err := os.MkdirAll(filepath.Dir(fullPath), 0755); err != nil {
						sp.logger.Debug("  â†³ åˆ›å»ºç›®å½•å¤±è´¥ / Failed to create directory: %v", err)
						continue
					}
					
					// ä»ç´¢å¼•æ£€å‡ºæ–‡ä»¶å†…å®¹ (git show :path)
					// Checkout file content from index (git show :path)
					cmd := exec.Command("git", "show", ":"+gitdirFile)
					cmd.Dir = sp.cfg.RepoRoot
					output, err := cmd.Output()
					if err != nil {
						sp.logger.Debug("  â†³ æ£€å‡ºå¤±è´¥ / Checkout failed: %s, %v", gitdirFile, err)
						continue
					}
					
					// å†™å…¥æ–‡ä»¶
					// Write file
					if err := os.WriteFile(fullPath, output, 0644); err != nil {
						sp.logger.Debug("  â†³ å†™å…¥å¤±è´¥ / Write failed: %s, %v", gitdirFile, err)
					}
				}
				sp.logger.Debug("  âœ“ å·²æ£€å‡º %d ä¸ª gitdir æ–‡ä»¶ / Checked out %d gitdir files", len(gitdirFiles), len(gitdirFiles))
			}
		}
		
		totalDuration := time.Since(startTime)
		cacheSize := sp.hashCache.Size()
		sp.logger.Info("é«˜æ€§èƒ½å®‰å…¨é‡å»ºå®Œæˆ / High-performance safe rebuild complete: %s (æ€»è€—æ—¶ / total: %v, ç¼“å­˜ / cache: %d)", 
			subrepoName, totalDuration, cacheSize)
	} else {
		sp.logger.Warn("æ— æ–‡ä»¶éœ€è¦å¤„ç† / No files to process: %s", subrepoName)
	}
	
	return nil
}

// collectWorkFiles æ”¶é›†å·¥ä½œæ–‡ä»¶ï¼ˆæ’é™¤è™šæ‹Ÿç¯å¢ƒï¼‰
// Collects work files (excluding virtual environments)
func (sp *SubrepoProcessor) collectWorkFiles(subrepoDir string) ([]string, []string, error) {
	var files []string
	var excludedDirs []string
	
	err := filepath.Walk(subrepoDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		
		// è·³è¿‡.gitç›®å½•
		// Skip .git directory
		if info.IsDir() && info.Name() == ".git" {
			return filepath.SkipDir
		}
		
		// è·³è¿‡è™šæ‹Ÿç¯å¢ƒç›®å½•
		// Skip virtual environment directories
		if info.IsDir() {
			for _, pattern := range config.VirtualEnvExcludePatterns {
				if info.Name() == pattern {
					relPath, _ := filepath.Rel(sp.cfg.RepoRoot, path)
					excludedDirs = append(excludedDirs, relPath)
					sp.logger.Debug("  âœ— æ’é™¤è™šæ‹Ÿç¯å¢ƒ / Excluding venv: %s", relPath)
					return filepath.SkipDir
				}
			}
		}
		
		// åªæ”¶é›†æ–‡ä»¶
		// Only collect files
		if !info.IsDir() {
			files = append(files, path)
		}
		
		return nil
	})
	
	return files, excludedDirs, err
}

// collectGitFiles æ”¶é›†.gitç›®å½•ä¸­çš„æ–‡ä»¶
// Collects files in .git directory
func (sp *SubrepoProcessor) collectGitFiles(subrepoDir string) ([]string, error) {
	gitDir := filepath.Join(subrepoDir, ".git")
	
	// æ£€æŸ¥.gitç›®å½•æ˜¯å¦å­˜åœ¨
	// Check if .git directory exists
	if _, err := os.Stat(gitDir); os.IsNotExist(err) {
		return []string{}, nil
	}
	
	var files []string
	
	err := filepath.Walk(gitDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		
		// åªæ”¶é›†æ–‡ä»¶
		// Only collect files
		if !info.IsDir() {
			files = append(files, path)
		}
		
		return nil
	})
	
	return files, err
}

// processWorkFile å¤„ç†å·¥ä½œæ–‡ä»¶
// Processes a work file
func (sp *SubrepoProcessor) processWorkFile(filePath string) (fileOperation, error) {
	relPath, _ := filepath.Rel(sp.cfg.RepoRoot, filePath)
	sp.logger.Debug("å¤„ç†å·¥ä½œæ–‡ä»¶ / Processing work file: %s", relPath)
	
	info, err := os.Stat(filePath)
	if err != nil {
		sp.logger.Warn("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ / Failed to stat file: %s, error: %v", relPath, err)
		return fileOperation{}, err
	}
	
	mode := "100644"
	if info.Mode()&0111 != 0 {
		mode = "100755"
		sp.logger.Debug("  â†³ å¯æ‰§è¡Œæ–‡ä»¶ / Executable file: mode=%s", mode)
	}
	
	// å°è¯•ä»ç¼“å­˜è·å–hash
	// Try to get hash from cache
	var hash string
	if cachedHash, ok := sp.hashCache.Get(filePath, info.ModTime(), info.Size()); ok {
		hash = cachedHash
		sp.logger.Debug("  âœ“ ä½¿ç”¨ç¼“å­˜ / Using cache (hash: %s)", hash[:8]+"...")
	} else {
		// è®¡ç®—hash
		// Compute hash
		hash, err = sp.gitOps.HashObject(filePath)
		if err != nil {
			sp.logger.Warn("è®¡ç®—hashå¤±è´¥ / Hash calculation failed: %s, error: %v", relPath, err)
			return fileOperation{}, err
		}
		
		sp.logger.Debug("  â†» è®¡ç®—hash / Computed hash: %s", hash[:8]+"...")
		
		// ç¼“å­˜hash
		// Cache hash
		sp.hashCache.Set(filePath, hash, info.ModTime(), info.Size())
	}
	
	sp.logger.Debug("  âœ“ å·²åŠ å…¥æ“ä½œé˜Ÿåˆ— / Added to operation queue")
	
	return fileOperation{
		mode: mode,
		hash: hash,
		path: relPath,
	}, nil
}

// processGitFile å¤„ç†.gitæ–‡ä»¶
// Processes a .git file
func (sp *SubrepoProcessor) processGitFile(filePath, subrepoDir string) (fileOperation, error) {
	info, err := os.Stat(filePath)
	if err != nil {
		return fileOperation{}, err
	}
	
	mode := "100644"
	if info.Mode()&0111 != 0 {
		mode = "100755"
	}
	
	hash, err := sp.gitOps.HashObject(filePath)
	if err != nil {
		return fileOperation{}, err
	}
	
	// è½¬æ¢è·¯å¾„: .git -> gitdir
	// Convert path: .git -> gitdir
	relPath, _ := filepath.Rel(sp.cfg.RepoRoot, filePath)
	targetPath := strings.Replace(relPath, "/.git/", "/gitdir/", 1)
	
	return fileOperation{
		mode: mode,
		hash: hash,
		path: targetPath,
	}, nil
}

// CleanOrphanedGitdirs æ¸…ç†å­¤å„¿gitdirç›®å½•
// Cleans orphaned gitdir directories
func (sp *SubrepoProcessor) CleanOrphanedGitdirs() error {
	sp.logger.Debug("é˜¶æ®µ1.5ï¼šæ¸…ç†å­¤å„¿gitdirç›®å½• / Phase 1.5: Cleaning orphaned gitdir directories")
	
	// æ–¹æ³•1: æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿä¸­çš„å­¤å„¿gitdir
	// Method 1: Check orphaned gitdir in filesystem
	for _, baseDir := range sp.cfg.SubrepoBaseDirs {
		basePath := filepath.Join(sp.cfg.RepoRoot, baseDir)
		
		if _, err := os.Stat(basePath); os.IsNotExist(err) {
			continue
		}
		
		// æŸ¥æ‰¾æ‰€æœ‰gitdirç›®å½•
		// Find all gitdir directories
		filepath.Walk(basePath, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return nil
			}
			
			if info.IsDir() && info.Name() == "gitdir" {
				parentDir := filepath.Dir(path)
				
				// æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦åªåŒ…å«gitdir
				// Check if parent directory only contains gitdir
				entries, err := os.ReadDir(parentDir)
				if err != nil {
					return nil
				}
				
				onlyGitdir := true
				for _, entry := range entries {
					if entry.Name() != "gitdir" {
						onlyGitdir = false
						break
					}
				}
				
				if onlyGitdir {
					sp.logger.Info("å‘ç°å­¤å„¿gitdirç›®å½• / Found orphaned gitdir: %s", filepath.Base(parentDir))
					sp.logger.Info("åˆ é™¤å­¤å„¿ç›®å½• / Removing orphaned directory: %s", parentDir)
					sp.logger.Debug("  â†³ å®Œæ•´è·¯å¾„ / Full path: %s", parentDir)
					
					if err := os.RemoveAll(parentDir); err != nil {
						sp.logger.Error("åˆ é™¤å¤±è´¥ / Remove failed: %v", err)
						return err
					}
					
					sp.logger.Debug("  âœ“ ç›®å½•å·²åˆ é™¤ / Directory removed")
					
					relPath, _ := filepath.Rel(sp.cfg.RepoRoot, parentDir)
					sp.gitOps.Add(relPath)
				}
			}
			
			return nil
		})
	}
	
	// æ–¹æ³•2: æ£€æŸ¥Gitç´¢å¼•ä¸­çš„å­¤å„¿gitdiræ–‡ä»¶
	// Method 2: Check orphaned gitdir files in git index
	sp.logger.Debug("æ£€æŸ¥Gitç´¢å¼•ä¸­çš„å­¤å„¿gitdiræ–‡ä»¶ / Checking orphaned gitdir files in Git index")
	
	files, err := sp.gitOps.ListFiles("--cached")
	if err != nil {
		return err
	}
	
	processedParents := make(map[string]bool)
	orphanedFiles := []string{}
	
	for _, file := range files {
		if !strings.Contains(file, "/gitdir/") {
			continue
		}
		
		// æå–çˆ¶ç›®å½•è·¯å¾„
		// Extract parent directory path
		parts := strings.Split(file, "/gitdir/")
		if len(parts) < 2 {
			continue
		}
		
		parentDir := parts[0]
		
		// æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡æ­¤çˆ¶ç›®å½•
		// Check if this parent directory has been processed
		if processedParents[parentDir] {
			continue
		}
		
		// æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦å­˜åœ¨
		// Check if parent directory exists
		parentPath := filepath.Join(sp.cfg.RepoRoot, parentDir)
		if _, err := os.Stat(parentPath); os.IsNotExist(err) {
			sp.logger.Warn("å‘ç°Gitç´¢å¼•ä¸­çš„å­¤å„¿gitdirçˆ¶ç›®å½• / Found orphaned gitdir parent directory: %s", parentDir)
			processedParents[parentDir] = true
			
			// æ”¶é›†è¯¥çˆ¶ç›®å½•ä¸‹çš„æ‰€æœ‰gitdiræ–‡ä»¶
			// Collect all gitdir files under this parent directory
			for _, f := range files {
				if strings.HasPrefix(f, parentDir+"/gitdir/") {
					orphanedFiles = append(orphanedFiles, f)
				}
			}
		}
	}
	
	// æ‰¹é‡åˆ é™¤å­¤å„¿gitdiræ–‡ä»¶
	// Batch delete orphaned gitdir files
	if len(orphanedFiles) > 0 {
		sp.logger.Info("æ¸…ç† %d ä¸ªå­¤å„¿gitdiræ–‡ä»¶ / Cleaning %d orphaned gitdir files", len(orphanedFiles), len(orphanedFiles))
		
		for _, file := range orphanedFiles {
			sp.logger.Debug("  â†³ åˆ é™¤ / Removing: %s", file)
			if err := sp.gitOps.Remove(file); err != nil {
				sp.logger.Error("åˆ é™¤å¤±è´¥ / Remove failed: %s, error: %v", file, err)
			}
		}
		
		sp.logger.Info("âœ“ å­¤å„¿æ–‡ä»¶æ¸…ç†å®Œæˆ / Orphaned files cleanup complete")
	}
	
	return nil
}

// batchUpdateIndex æ‰¹é‡æ›´æ–°Gitç´¢å¼•ï¼ˆå¸¦é”æ£€æµ‹å’Œé‡è¯•æœºåˆ¶ï¼‰
// Batch updates git index (with lock detection and retry mechanism)
func (sp *SubrepoProcessor) batchUpdateIndex(operations []fileOperation) error {
	if len(operations) == 0 {
		return nil
	}
	
	// æ„å»ºç´¢å¼•ä¿¡æ¯å­—ç¬¦ä¸²
	// Build index info string
	// æ ¼å¼ï¼šmode hash path
	// Format: mode hash path
	var indexInfo strings.Builder
	for _, op := range operations {
		indexInfo.WriteString(fmt.Sprintf("%s %s\t%s\n", op.mode, op.hash, op.path))
	}
	
	// æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆä½¿ç”¨é…ç½®å€¼ï¼‰
	// Maximum retry count (using config values)
	maxRetries := sp.cfg.IndexUpdateMaxRetries
	retryDelay := sp.cfg.IndexUpdateRetryDelay
	
	for attempt := 1; attempt <= maxRetries; attempt++ {
		// æ£€æŸ¥å¹¶æ¸…ç†è¿‡æœŸçš„ index.lock æ–‡ä»¶
		// Check and clean stale index.lock file
		lockPath := filepath.Join(sp.cfg.RepoRoot, ".git", "index.lock")
		if info, err := os.Stat(lockPath); err == nil {
			lockAge := time.Since(info.ModTime())
			sp.logger.Debug("[LOCKæ£€æµ‹] index.lock å­˜åœ¨ï¼Œå¹´é¾„: %v / index.lock exists, age: %v", lockAge, lockAge)
			
			// å¦‚æœ lock æ–‡ä»¶è¶…è¿‡é…ç½®æ—¶é—´ï¼Œè®¤ä¸ºæ˜¯æ®‹ç•™æ–‡ä»¶
			// If lock file is older than configured time, consider it stale
			if lockAge > sp.cfg.LockFileMaxAge {
				sp.logger.Warn("[LOCKæ¸…ç†] æ¸…ç†è¿‡æœŸçš„ index.lock (å¹´é¾„: %v) / Cleaning stale index.lock (age: %v)", lockAge, lockAge)
				if err := os.Remove(lockPath); err != nil {
					sp.logger.Warn("[LOCKæ¸…ç†] æ¸…ç†å¤±è´¥ / Cleanup failed: %v", err)
				} else {
					sp.logger.Info("[LOCKæ¸…ç†] è¿‡æœŸ lock æ–‡ä»¶å·²æ¸…ç† / Stale lock file cleaned")
				}
			} else {
				// lock æ–‡ä»¶è¾ƒæ–°ï¼Œå¯èƒ½æœ‰å…¶ä»–è¿›ç¨‹æ­£åœ¨ä½¿ç”¨
				// Lock file is recent, another process might be using it
				sp.logger.Debug("[LOCKç­‰å¾…] lock æ–‡ä»¶è¾ƒæ–°ï¼Œç­‰å¾…é‡Šæ”¾... / Lock file is recent, waiting for release...")
				time.Sleep(retryDelay)
				continue
			}
		}
		
		// ä½¿ç”¨å•ä¸ªgit update-index --index-infoå‘½ä»¤æ‰¹é‡æ›´æ–°
		// Use single git update-index --index-info command for batch update
		sp.logger.Debug("[INDEXæ›´æ–°] å°è¯• %d/%d: æ‰¹é‡æ›´æ–° %d ä¸ªæ–‡ä»¶ / Attempt %d/%d: Batch updating %d files", 
			attempt, maxRetries, len(operations), attempt, maxRetries, len(operations))
		
		cmd := exec.Command("git", "update-index", "--index-info")
		cmd.Dir = sp.cfg.RepoRoot
		cmd.Stdin = strings.NewReader(indexInfo.String())
		
		var stderr bytes.Buffer
		cmd.Stderr = &stderr
		
		if err := cmd.Run(); err != nil {
			stderrStr := stderr.String()
			
			// æ£€æŸ¥æ˜¯å¦æ˜¯ lock æ–‡ä»¶å†²çª
			// Check if it's a lock file conflict
			if strings.Contains(stderrStr, "index.lock") || strings.Contains(stderrStr, "æ–‡ä»¶å·²å­˜åœ¨") {
				sp.logger.Warn("[INDEXæ›´æ–°] å°è¯• %d/%d å¤±è´¥: index.lock å†²çª / Attempt %d/%d failed: index.lock conflict", 
					attempt, maxRetries, attempt, maxRetries)
				
				if attempt < maxRetries {
					sp.logger.Info("[INDEXæ›´æ–°] ç­‰å¾… %v åé‡è¯•... / Waiting %v before retry...", retryDelay, retryDelay)
					time.Sleep(retryDelay)
					// å¢åŠ é‡è¯•å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼‰
					// Increase retry delay (exponential backoff)
					retryDelay = retryDelay * 2
					continue
				}
			}
			
			return fmt.Errorf("git update-index --index-info failed: %v, stderr: %s", err, stderrStr)
		}
		
		// æˆåŠŸ
		// Success
		sp.logger.Debug("[INDEXæ›´æ–°] æˆåŠŸï¼æ‰¹é‡æ›´æ–°äº† %d ä¸ªæ–‡ä»¶çš„ç´¢å¼• / Success! Batch updated index for %d files", len(operations), len(operations))
		return nil
	}
	
	return fmt.Errorf("git update-index failed after %d retries", maxRetries)
}

// batchRemoveFiles æ‰¹é‡åˆ é™¤æ–‡ä»¶
// Batch removes files
func (sp *SubrepoProcessor) batchRemoveFiles(files []string) error {
	if len(files) == 0 {
		return nil
	}
	
	sp.logger.Info("æ‰¹é‡åˆ é™¤ %d ä¸ªæ–‡ä»¶ / Batch removing %d files", len(files), len(files))
	
	// åˆ†æ‰¹å¤„ç†ï¼ˆä½¿ç”¨é…ç½®çš„æ‰¹æ¬¡å¤§å°ï¼‰
	// Process in batches (using configured batch size)
	batchSize := sp.cfg.BatchSize
	sp.logger.Debug("  â†³ æ‰¹æ¬¡å¤§å° / Batch size: %d", batchSize)
	
	successCount := 0
	failedFiles := []string{}
	
	for i := 0; i < len(files); i += batchSize {
		end := i + batchSize
		if end > len(files) {
			end = len(files)
		}
		
		batch := files[i:end]
		batchNum := (i / batchSize) + 1
		totalBatches := (len(files) + batchSize - 1) / batchSize
		
		sp.logger.Debug("  â†³ å¤„ç†æ‰¹æ¬¡ %d/%d / Processing batch %d/%d (%d files)", 
			batchNum, totalBatches, batchNum, totalBatches, len(batch))
		
		// è¯¦ç»†è®°å½•æ¯ä¸ªæ–‡ä»¶ (æ‰¹æ¬¡å°äºç­‰äº10ä¸ªæ–‡ä»¶æ—¶)
		// Detailed logging for small batches
		if len(batch) <= 10 {
			for _, f := range batch {
				sp.logger.Debug("    â€¢ %s", f)
			}
		} else {
			sp.logger.Debug("    â€¢ %s ... (å…±%dä¸ªæ–‡ä»¶)", batch[0], len(batch))
		}
		
		// ä½¿ç”¨git rmæ‰¹é‡åˆ é™¤
		// Use git rm to batch remove files
		cmd := exec.Command("git", append([]string{"rm", "--cached", "--ignore-unmatch", "--"}, batch...)...)
		cmd.Dir = sp.cfg.RepoRoot
		
		var stderr bytes.Buffer
		cmd.Stderr = &stderr
		
		if err := cmd.Run(); err != nil {
			sp.logger.Debug("æ‰¹æ¬¡ %d åˆ é™¤å¤±è´¥ (å·²å¿½ç•¥) / Batch %d remove failed (ignored): %v", batchNum, batchNum, err)
			if stderr.Len() > 0 {
				sp.logger.Debug("  â†³ stderr: %s", stderr.String())
			}
			failedFiles = append(failedFiles, batch...)
		} else {
			successCount += len(batch)
			sp.logger.Debug("  âœ“ æ‰¹æ¬¡ %d å®Œæˆ / Batch %d complete", batchNum, batchNum)
		}
	}
	
	// æ€»ç»“
	// Summary
	if len(failedFiles) > 0 {
		sp.logger.Warn("æ‰¹é‡åˆ é™¤å®Œæˆï¼Œä½†æœ‰ %d ä¸ªæ–‡ä»¶å¤±è´¥ / Batch remove complete, but %d files failed", len(failedFiles), len(failedFiles))
		sp.logger.Debug("å¤±è´¥æ–‡ä»¶åˆ—è¡¨ / Failed files:")
		for _, f := range failedFiles {
			sp.logger.Debug("  â€¢ %s", f)
		}
	} else {
		sp.logger.Info("âœ“ æ‰¹é‡åˆ é™¤å®Œæˆ / Batch remove complete: %d files", successCount)
	}
	
	return nil
}

// unquoteGitPath å»é™¤Gitå¼•å·å¹¶è§£ç å…«è¿›åˆ¶è½¬ä¹‰åºåˆ—
// Removes Git quotes and decodes octal escape sequences
// Gitå¯¹åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡ã€ç©ºæ ¼ç­‰ï¼‰çš„è·¯å¾„ä¼šæ·»åŠ å¼•å·å¹¶ä½¿ç”¨å…«è¿›åˆ¶è½¬ä¹‰
// Git adds quotes and uses octal escapes for paths with special characters (like Chinese, spaces, etc.)
// ä¾‹å¦‚ / Example: "debian/data/git/dev/\345\220\216\347\253\257" -> debian/data/git/dev/åç«¯
func unquoteGitPath(path string) string {
	// æ£€æŸ¥æ˜¯å¦è¢«å¼•å·åŒ…å›´
	// Check if surrounded by quotes
	if len(path) >= 2 && path[0] == '"' && path[len(path)-1] == '"' {
		// å»é™¤å¼•å·
		// Remove quotes
		path = path[1 : len(path)-1]
		
		// è§£ç å…«è¿›åˆ¶è½¬ä¹‰åºåˆ—ï¼ˆå¦‚ \345\220\216 -> åï¼‰
		// Decode octal escape sequences (e.g., \345\220\216 -> å)
		var result strings.Builder
		i := 0
		for i < len(path) {
			if path[i] == '\\' && i+3 < len(path) {
				// æ£€æŸ¥æ˜¯å¦æ˜¯å…«è¿›åˆ¶è½¬ä¹‰åºåˆ—ï¼ˆ\ddd æ ¼å¼ï¼‰
				// Check if it's an octal escape sequence (\ddd format)
				if isOctalDigit(path[i+1]) && isOctalDigit(path[i+2]) && isOctalDigit(path[i+3]) {
					// è§£æå…«è¿›åˆ¶å€¼
					// Parse octal value
					octalStr := path[i+1 : i+4]
					if val, err := strconv.ParseInt(octalStr, 8, 32); err == nil {
						result.WriteByte(byte(val))
						i += 4
						continue
					}
				}
				// å¤„ç†å…¶ä»–è½¬ä¹‰åºåˆ—
				// Handle other escape sequences
				if i+1 < len(path) {
					switch path[i+1] {
					case 'n':
						result.WriteByte('\n')
						i += 2
						continue
					case 't':
						result.WriteByte('\t')
						i += 2
						continue
					case '\\':
						result.WriteByte('\\')
						i += 2
						continue
					case '"':
						result.WriteByte('"')
						i += 2
						continue
					}
				}
			}
			result.WriteByte(path[i])
			i++
		}
		return result.String()
	}
	return path
}

// isOctalDigit æ£€æŸ¥å­—ç¬¦æ˜¯å¦æ˜¯å…«è¿›åˆ¶æ•°å­—
// Checks if a character is an octal digit
func isOctalDigit(c byte) bool {
	return c >= '0' && c <= '7'
}
